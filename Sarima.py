import pandas as pd
import matplotlib.pyplot as plt
import calendar
import numpy as np
import itertools
import warnings
from statsmodels.graphics.tsaplots import plot_pacf



data = pd.read_csv("Sales.csv")
dates = pd.date_range(start='2016-01-01', freq='MS', periods=len(data))
#print(dates)

data["Month"]=dates.month
data.head()
data["Year"]=dates.year



data["Month"]=data["Month"].apply(lambda x: calendar.month_abbr[x])   # Convert the numerical months (1-12) into abbreviated English names (e.g. Jan, Feb, etc.), making the data more intuitive and facilitating subsequent visualization and group analysis.

data.drop(["Month-Year"],axis=1,inplace=True)  # Delete the original Month-Year string column (as a more standard time index has been established through dates)
data.rename(columns={"Number of Sold":"Sale"},inplace=True)   # Simplify the "Number of Tractor Sold" column to "Sale" to facilitate code writing (make the variable shorter).
data.set_index(dates,inplace=True)  # Take the standard time index dates previously generated by pd.date_range() as the new index of data. In this way, there will be a time series DataFrame, with each row corresponding to the sales volume of one month.

data.set_index(dates,inplace=True)
df = data.copy()
df.drop(["Month","Year"],axis=1,inplace=True)

from datetime import datetime

# Plot graph
plt.xlabel("Date")
plt.ylabel("Sale")
plt.plot(df)
# plt.show()

#determining rolling statistics,Calculate the rolling mean and standard deviation of the time series to determine whether it is stationary
rolmean=df.rolling(window=12).mean()
rolstd=df.rolling(window=12).std()
# print(rolmean,rolstd)


#plot roll statistics, If the red line (mean) is at the basic level and the black line (standard deviation) fluctuates little → the data may be stable. If the red line shows a trend of rising or falling and the black line changes sharply → the data is unstable
orig=plt.plot(df,color="blue",label="Original")
mean=plt.plot(rolmean,color="red",label="Rolling Mean")
std=plt.plot(rolstd,color="black",label="Rolling Std")
plt.legend(loc="best")
plt.title("Rolling mean and std")
plt.show()

#Perform Seasonal Decomposition on the time series to break down it into three components: trend, seasonality and residual
from statsmodels.tsa.seasonal import seasonal_decompose
ts_decompose=seasonal_decompose(df,model="multiplicative",period=12)
ts_decompose.plot()
plt.show()




#The autocorrelation function (ACF) and the partial autocorrelation function (PACF) are used to determine the correlation of sequences and help identify the parameters p (AR order) and q (MA order) in the ARIMA model.
#plot ACF and PACF
from statsmodels.tsa.stattools import acf,pacf

lag_acf=acf( df, nlags=20)
lag_pacf=pacf( df,nlags=20,method="ols")

#plot ACF shows the variation of the autocorrelation coefficient with the lag order. The zero line in the middle indicates no correlation. The two dotted lines above and below represent the confidence interval (95% confidence level), and the coefficients beyond this line are significantly non-zero.
plt.subplot(121)
plt.plot(lag_acf)
plt.axhline(y=0,linestyle='--',color="gray")
plt.axhline(y=-1.96/np.sqrt(len(df)),linestyle="--",color="gray")
plt.axhline(y=1.96/np.sqrt(len(df)),linestyle="--",color="gray")
plt.title("Autocorrleation function")
plt.xlim([0,20])


#Plot PACF: Draw the partial autocorrelation coefficient. Its function is similar to ACF, but it eliminates the influence of intermediate lag orders, making it more suitable for determining the order of the AR part.
plt.subplot(122)
plt.plot(lag_pacf)
plt.axhline(y=0,linestyle='--',color="gray")
plt.axhline(y=-1.96/np.sqrt(len(df)),linestyle="--",color="gray")
plt.axhline(y=1.96/np.sqrt(len(df)),linestyle="--",color="gray")
plt.title("partial autocorrleation function")
plt.xlim([0,20])
plt.tight_layout()
# The peaks that are significantly (outside the confidence interval) in the ACF plot usually indicate the q-order of the MA model. The significant lag orders in the PACF plot are used to determine the p-order of the AR model.



# Null hypothesis rejected only For lag=1 (i.e. auto_correlation is statisticaly significant)
pacf_plot=plot_pacf(df,lags=20)


# Define the d and q parameters to take any value between 0 and 1
q = d = range(0, 2)
# Define the p parameters to take any value between 0 and 3
p = range(0, 4)

# Generate all different combinations of p, q and q triplets
pdq = list(itertools.product(p, d, q))

# Generate all different combinations of seasonal p, q and q triplets
seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]

print('Examples of parameter combinations for Seasonal ARIMA...')
print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))
print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))
print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))
print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))



# The SARIMAX model Grid Search (Grid Search) finds the optimal model with the minimum AIC (Akaiike Information Criterion) in the given parameter space.
warnings.filterwarnings("ignore") # specify to ignore warning messages
import statsmodels.api as sm



AIC = []
SARIMAX_model = []

for param in pdq:
    for param_seasonal in seasonal_pdq:
        try:
            mod = sm.tsa.statespace.SARIMAX(df,
                                            order=param,
                                            seasonal_order=param_seasonal,
                                            enforce_stationarity=False,
                                            enforce_invertibility=False)

            results = mod.fit()
            print(f'Success: SARIMAX{param}x{param_seasonal} - AIC:{results.aic}')
            AIC.append(results.aic)
            SARIMAX_model.append([param, param_seasonal])
        except Exception as e:
            print(f'Fail: SARIMAX{param}x{param_seasonal} - {e}')
            continue
print('The smallest AIC is {} for model SARIMAX{}x{}'.format(min(AIC), SARIMAX_model[AIC.index(min(AIC))][0],SARIMAX_model[AIC.index(min(AIC))][1]))


SARIMAX_model[AIC.index(min(AIC))][0]
SARIMAX_model[AIC.index(min(AIC))][1]

mod=sm.tsa.statespace.SARIMAX(df,
                             order=SARIMAX_model[AIC.index(min(AIC))][0],
                             seasonal_order=SARIMAX_model[AIC.index(min(AIC))][1],
                             eforce_stationarity=False,
                             enforce_invertibility=False)
results=mod.fit()

results.plot_diagnostics(figsize=(20,14))
plt.show()

df.tail()

df.head()

# One-step Prediction
pred0 = results.get_prediction(start="2016-01-01", dynamic=False)
pred0_ci = pred0.conf_int()

# Dynamic prediction (using only previous predicted values to predict the future)
pred1 = results.get_prediction(start="2016-01-01", dynamic=True)
pred1_ci = pred1.conf_int()

# Future prediction (Beyond the original data range, next 12 months)
pred2 = results.get_forecast(steps=12)
pred2_ci = pred2.conf_int()


ax = df.plot(figsize=(20, 10))
pred0.predicted_mean.plot(ax=ax, label="1-Step-ahead forecast (dynamic=False)")
pred1.predicted_mean.plot(ax=ax, label="Dynamic forecast (dynamic=True)")
pred2.predicted_mean.plot(ax=ax, label="Forecast beyond data (steps=12)")
ax.fill_between(pred2_ci.index,
                pred2_ci.iloc[:, 0],
                pred2_ci.iloc[:, 1],
                color='k', alpha=.1)

plt.xlabel("Date")
plt.ylabel("Sale")
plt.title("SARIMA预测可视化")
plt.legend()
plt.show()



y_actual=df["Sale"]
y_pred=pred0.predicted_mean
from sklearn.metrics import mean_absolute_error
MAE=mean_absolute_error(y_actual,y_pred)


from sklearn.metrics import mean_squared_error
MSE=mean_squared_error(y_actual,y_pred)


RMSE=np.sqrt(MSE)

RMSE=np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100
